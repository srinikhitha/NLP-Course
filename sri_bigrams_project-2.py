# -*- coding: utf-8 -*-
"""Sri_Bigrams_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vp_Oti9nN-IWjIND0HlojCGNCIDTGOfe
"""

pip install nltk==3.5

"""I am trying to use NLTK library to do Bigrams Project"""

import nltk

from nltk.tokenize import word_tokenize

nltk.download('punkt')

"""I need to download txt file from blackboard link as i am using google collab not python in my local"""

import os

!wget -q 'https://learn-us-east-1-prod-fleet01-beaker-xythos.content.blackboardcdn.com/5a31b16bb2c48/22390681?X-Blackboard-S3-Bucket=learn-xythos-edge-pr-otdt8jd8o9r1q7dp6ohjmnw5fghpnuse1b-s3alias&X-Blackboard-Expiration=1738378800000&X-Blackboard-Signature=YiRiFLyhFFziVhY0rutAVMyEgl2qhxWWcNxBmrTcu80%3D&X-Blackboard-Client-Id=305918&X-Blackboard-S3-Region=us-east-1&response-cache-control=private%2C%20max-age%3D21600&response-content-disposition=inline%3B%20filename%2A%3DUTF-8%27%27Nyt.200811.txt&response-content-type=text%2Fplain&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIGcEZtRjXXsD4Y0g5C45LoHK1hrGPWXPRUBpBikq1PiEAiBOC5woJtH1po3mBo9SiR8TE%2BRTjU3c2acL7U2RYZLyYiq8BQjI%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDU1NjkwMzg2MTM2MSIMWuYCKXqrYqTpMJZNKpAFOXFuRXJd2bpCyLgpb3wd1DYFdo7uZtO%2BvnG66k7tYNd0SJv52AqlvZavYYWHwlBTLdGovHWn1oYvMxVJqRVh5AUIFfuxZKy1236k%2Bt9TnHA0CBYuSYlh%2FiToWOaqVSfU1KlcLBPosYxIPFzW%2FkWMDGHHzkL48bhSlzmpyHJXOhYheViX57j9QhK43NZeeOmEVhMJ3qrfYp0rlRhv3iLlIf3fVAS4uz96sEE7triTVXjr6qCY6KRFnQcp4Xvk6AjWn6rMuUQxPH7AwcwbqY4rQaVZEaiWxZEsGrugmkaxAhmaZKpNhStTnFcUuMj505nDVh1ilZbU7kMK1H23zYFO%2FXPJdgc%2F8aYp0GV4OD4iDsD7RsPrSvCPJh%2Fz1Sokpd15vDzEcKjgM4NcI1FUdwNAgiRBR2RRvoM7flAWQsxJgWRNumFmD%2Bjs8p%2FLJ%2BTp8OHVGklqFIgyXrnqWwTgD3pqu5Y3T7%2FbY5BOIU8GKuEZeyExHwDR6aXNZigrEpOqbP0ak2so5eHQYJATrR1AjXRUhFdfw1B4Z%2BT2AdrZPBA6AESL6wfM6CQ7f4U6t6X7TS4y4Lbf7SNXQu1Ab9BCBpMX7bDrsQGZm0cnV%2FfIbZ3M25SdB8UjU3LH2pGHng%2BRiv%2FYCFjNNzCkC46j5ua8%2Bpt%2FYW9M73YaeSga5%2BhrocYDOgF89kupoWNh4%2FWPrAxsEcaYfGQ%2BCeq9nhaOIIyLnoIs%2FD3J17uyOvCKIBQjYfa2wib7XghRZADBOJeDvtB8C8vTwgyXrCc3yKJHi5DDRAVNUkEv1KzEwhc2WTACUcCZ4tlHAjXvFQ9pnYRhKtDfM9dHKTfkU0opGDzTD%2FzrglG5TArMpRHCIL28WJB1iSIAHeQwqp%2F1vAY6sgGlsZTtHuVz%2FayXaGNfi9M5D8CrnsTNdp29ld8vW71FaL6R8RO3YqC%2F%2Fn7zEAAdMmzVx4Qy49WJXWRoldq%2B7A%2FgPt7aiiAa10cebdGORl1mwbc5advsGWiYnrHgj%2BzZdHi9NWYg%2FHO6bIG6JhyLT0vsZFNGyb1LW%2FIdmev0c3Pu0Rou6%2FRM9TB7YPSn8mZ9sXJxcN6pWYp8YhuFU%2FGFegQWHtDtL5eQtfwphRtv2Q2XdWsn&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250131T210000Z&X-Amz-SignedHeaders=host&X-Amz-Expires=21600&X-Amz-Credential=ASIAYDKQORRYTGFPOAHX%2F20250131%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=759545ef232520cb3a72d9e87d5ac2df363197ba940bbaa22f1555b2d39d4990' -O 'Nyt.200811.txt'

"""we can use another way to download the txt file to collab environment"""

import urllib.request

url = 'https://learn-us-east-1-prod-fleet01-beaker-xythos.content.blackboardcdn.com/5a31b16bb2c48/22390681?X-Blackboard-S3-Bucket=learn-xythos-edge-pr-otdt8jd8o9r1q7dp6ohjmnw5fghpnuse1b-s3alias&X-Blackboard-Expiration=1738389600000&X-Blackboard-Signature=cg8nl%2BBniCMjFQfonSi4xuyjDC7ICH4Zs3SdyD%2BF4ds%3D&X-Blackboard-Client-Id=305918&X-Blackboard-S3-Region=us-east-1&response-cache-control=private%2C%20max-age%3D21600&response-content-disposition=inline%3B%20filename%2A%3DUTF-8%27%27Nyt.200811.txt&response-content-type=text%2Fplain&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEMH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIFCz0F6EOTl0%2BG25utVQDiAucfM4giZNuvn8QmLa81dUAiBxLTLNYMG84BjtaMXKu0q%2BkdTEysIAusNoaiKFt3T0fiq8BQjJ%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDU1NjkwMzg2MTM2MSIMiriaUQzWt2m26iJmKpAF8j%2BUYcLeWKFGBfvEkY84HbnHHI4vbKrfuaYpTmwkkVlR1MyYF4w0f1sSdvLsBM6FN48opvAA8CR4iQAJpAvKO4c6VppnwaTtG%2FZLK7VTUG9zxbXCDCi0TVnUxc8UueCW1gqroWvdRYjgMaVGRWkMxkxxb%2F5iyhYKXe5ezAxPTR3krFP7%2FX3RzL1UMcF4LQqmbiWRPw8uDYgCwkCeOgjEuxkt%2BeNl3eNnqkvw3OmsEp%2BhCGYTkjOHpcpXfx0O1ZHHIL51ahs42uAA1PdCbxinCbAMQwoTX8oM%2FL4MIor0UrpdMRGDkwsyuWYGAAgpaqQX7fcaRFdGGdIE4XP0lpmOyqbonGZxixgE1l%2BCcpzOxIcO6XAqr2pLeB599kjcUaNsoduWdHzOf9mQ5m9ibNtfEqPRHzYd34a3i2nn16F%2BfnP31uaTd2bPut%2FKVArDzKa3BKZkOMTwZphpR8jrk9KWI2nhYbB1%2B8ckdee7TcU8EiHHo77ZzHGnh96UpJLYa3amWOifjREwVR5KXHUEHU259%2FxBJay5V9gaK4oky%2FCGvIvOANMalNYeRS6J2imQm%2BA8%2FH0DcJvpiwrSUOzIFI5GDqPgYNIGsj0xbtXqNaJqlRfMc%2BfLKSv7H101fDNeTHUznsX66BrNdA4rvlxF0KgzrJA%2Fd8Iu84G7AA8Ojj%2FxjjhfriC45EMyYu5esrrvPdDma38ij47GMqWJ8nzdIh94wB8s3xuknqasx6rkohuKRh8J43o2lzy4yEaOkY%2By4vXPmWKJDVGQl8NfU%2FsXpvKaUBnW6MNByaet1N59wrX96qDmxQZd%2F%2Bu66mC%2BScmCnVOHIS5%2Bk5mJGroUdPeCsgazUpldf4ZzDcVr6Iu2wsSgVT8wt8%2F1vAY6sgHozpnP0xjr9W4mOTgYYUpuULQ0pgyKmwW4qb8KsSXfmT9o%2FBgUoqmrtHHy3MvYIvyS%2BxOxtXSkNsTCO6zgoHUd060fU1YnAGc5uvx6rzNNwVzZtX6fOYLTYHoybJGwvfkb1t8p5zg5tHVWpGbNmhkOFwoFR%2B6eODvsDqhlGHxgUVPTYqqbmUbqi2piowb%2Bfu9Qe0ZWmnOeo1yQNkukP%2ByZB4tzvXx%2BXZmfrS842tvld%2FcE&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250201T000000Z&X-Amz-SignedHeaders=host&X-Amz-Expires=21600&X-Amz-Credential=ASIAYDKQORRY74GB2UE3%2F20250201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=cf00f8db11c7e0dea6179382ad35f22428e5509c754541f3e180fceabfaabd11'
filename = 'Nyt.200811.txt'
urllib.request.urlretrieve(url, filename)

"""Reading the file"""

with open("Nyt.200811.txt", "r") as file:
    text = file.read()

"""1. Tokenize by word

For this task i used NLTK
"""

from nltk.tokenize import word_tokenize

tokens = word_tokenize(text)

"""Removing punctuation"""

import string

filtered_tokens = [word for word in tokens if word not in string.punctuation]



"""I am creating bigrams using ngrams from NLTK"""

from nltk.util import ngrams

bigrams_sri = list(ngrams(filtered_tokens, 2))

from collections import Counter

bigram_counts = Counter(bigrams_sri)

"""Displaying all the bigrams from the txt"""

for bigram, count in bigram_counts.items():
    print(f"Bigrams of Nyt.200811.txt: {bigram}, Count: {count}")

"""Getting the top 15 from most commom bigrams"""

top_15_bigrams = bigram_counts.most_common(15)

for bigram, count in top_15_bigrams:
    print(f"Bigrams of Nyt.200811.txt:{bigram}, {count}")

"""2. Create two almost-duplicate files of words, off by one line, using tail.

First we need to copy original text file matter to duplicate file.
"""

with open("Sri_bigrams_words.txt", "w") as outfile:
       for token in tokens:
           outfile.write(token + "\n")

!cp Sri_bigrams_words.txt Sri_bigrams_words_duplicate.txt

!tail -n +1 Sri_bigrams_words.txt | head -n -1 > Sri_bigrams_words_duplicate.txt

"""We can use another way to do copy"""

!tail -n +1 Sri_bigrams_words.txt > Sri_bigrams_words_duplicate1.txt

!tail -n +2 Sri_bigrams_words.txt > Sri_bigrams_words_duplicate2.txt

"""In the above command i am copying the lines from the original text to duplicate text file from second line in this way we are off by one line

Now we can check the file
"""

!cat Sri_bigrams_words.txt

!cat Sri_bigrams_words_duplicate.txt

!cat Sri_bigrams_words_duplicate1.txt

!cat Sri_bigrams_words_duplicate2.txt

"""3. Paste them together so as to get word(i) and word(i +1) on the same line.

For this task i used paste from NLTK
"""

!paste Sri_bigrams_words_duplicate1.txt Sri_bigrams_words_duplicate2.txt > bigrams_sri_combine.txt

"""4. Then, after you have the data from the procedure above: Provide the commands to find the 10 most common bigrams.

For doing the above task i used most common method
"""

top_10_bigrams = bigram_counts.most_common(10)

for bigram, count in top_10_bigrams:
    print(f"Bigrams of bigrams_sri_combine.txt:{bigram}, {count}")